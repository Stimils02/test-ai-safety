people:
  # ------------------------------------------------------------------------------------------------------------
  # ----------------------------------------------- LEADERSHIP -------------------------------------------------
  # ------------------------------------------------------------------------------------------------------------
  - name: "Eugene Bagdasarian"
    email: "eugene@umass.edu"
    categories:
      - "Faculty"
      - "Leadership"
    position: "Assistant Professor"
    ais_title: "Lead"
    description: "Eugene Bagdasarian is an Assistant Professor at UMass Amherst and a Director of the AI Safety Initiative. His research focuses on trustworthy machine learning, with an emphasis on robustness, interpretability, and alignment of AI systems."
    website: "https://people.cs.umass.edu/~eugene/"
    image: "content/people/images/Eugene Bagdasarian.jpg"
    office: "CS 3XX"
    interests: ["Trustworthy ML", "AI Alignment", "Robustness", "Interpretability"]

  - name: "Shlomo Zilberstein"
    email: "shlomo@cs.umass.edu"
    categories:
      - "Faculty"
      - "Leadership"
    position: "Professor"
    ais_title: "Lead"
    description: "Shlomo Zilberstein is a Professor of Computer Science and former Associate Dean of Research and Engagement. Zilbersteinâ€™s research focuses on the foundations and applications of resource-bounded reasoning techniques, which allow complex systems to make decisions while coping with uncertainty, missing information, and limited computational resources. His research interests include automated reasoning, planning and learning under uncertainty, multi-agent systems, Markov decision processes, design of autonomous agents, meta-reasoning and meta-level control, self-driving vehicles, human-centered AI, safe and ethical AI."
    website: "https://groups.cs.umass.edu/shlomo/"
    image: "content/people/images/Shlomo Zilberstein.jpg"
    office: "A359 LGRC"
    interests: ["Artificial Intelligence", "Automated Planning", "Multiagent Systems", "Autonomous Agents", "Bounded Rationality"]

  - name: "Kyle Hollins Wray"
    email: "kwray@umass.edu"
    categories:
      - "Research Fellow"
      - "Leadership"
    position: "Research Fellow"
    ais_title: "Lead"
    description: "Kyle Hollins Wray is an Research Fellow at UMass Amherst and the Executive Director of the AI Safety Initiative. He leads the creation of autonomous robots that can plan, make decisions, navigate, and coordinate in the real world. He also researches theoretical models and practical algorithms for decision-making under uncertainty in real robots. AI Safety is a top priority among all his work."
    website: "https://wray.ai"
    image: "content/people/images/Kyle Hollins Wray.jpg"
    office: "N/A"
    interests: ["AI Safety", "Decision Making", "Autonomous Robotics", "Multi-Objective Models"]

  # ------------------------------------------------------------------------------------------------------------
  # --------------------------------------------- ADVISORY BOARD -----------------------------------------------
  # ------------------------------------------------------------------------------------------------------------
  # Fake
  - name: "Dr. Elizabeth Chen"
    email: "echen@stanford.edu"
    categories:
      - "Advisory Board"
    position: "Professor of Computer Science, Stanford University"
    ais_title: "Advisory Board Member"
    description: "Dr. Chen is a leading researcher in AI ethics and governance. Her work focuses on developing frameworks for responsible AI innovation."
    website: "https://stanford.edu/~echen/"
    image: "content/people/images/pic_placeholder.jpg"
    interests: ["AI Ethics", "Governance", "Responsible Innovation"]
    
  # ------------------------------------------------------------------------------------------------------------
  # ---------------------------------------- POSTDOCTORAL SCHOLARS ---------------------------------------------
  # ------------------------------------------------------------------------------------------------------------
  # Fake
  - name: "Dr. Lisa Chen"
    email: "lchen@umass.edu"
    categories:
      - "Postdoctoral Researcher"
    position: "Postdoctoral Researcher"
    ais_title: "Postdoctoral Researcher"
    description: "Dr. Chen works on interpretability methods for large language models."
    website: "https://people.cs.umass.edu/~lchen/"
    image: "content/people/images/pic_placeholder.jpg"
    office: "CS Building, Room 501"
    interests: ["LLM Interpretability", "NLP", "AI Safety"]

  # Fake
  - name: "Dr. David Kim"
    email: "dkim@umass.edu"
    categories:
      - "Postdoctoral Researcher"
    position: "Postdoctoral Researcher"
    ais_title: "Postdoctoral Researcher"
    description: "Dr. Kim researches robustness in reinforcement learning systems."
    website: "https://people.cs.umass.edu/~dkim/"
    image: "content/people/images/pic_placeholder.jpg"
    office: "CS Building, Room 502"
    interests: ["Reinforcement Learning", "Robustness", "Safety"]

  # ------------------------------------------------------------------------------------------------------------
  # ---------------------------------------- GRADUATE STUDENTS -------------------------------------------------
  # ------------------------------------------------------------------------------------------------------------
  # Fake
  - name: "Alex Johnson"
    email: "ajohnson@umass.edu"
    categories:
      - "Graduate Student"
    position: "PhD Candidate"
    ais_title: "Graduate Researcher"
    description: "Alex's dissertation focuses on scalable oversight methods for AI systems."
    website: "https://people.cs.umass.edu/~ajohnson/"
    image: "content/people/images/pic_placeholder.jpg"
    office: "CS Building, Room 601"
    interests: ["Scalable Oversight", "AI Safety", "Alignment"]

  # Fake
  - name: "Maya Patel"
    email: "mpatel@umass.edu"
    categories:
      - "Graduate Student"
    position: "PhD Candidate"
    ais_title: "Graduate Researcher"
    description: "Maya researches explainable AI and human-interpretable models."
    website: "https://people.cs.umass.edu/~mpatel/"
    image: "content/people/images/pic_placeholder.jpg"
    office: "CS Building, Room 602"
    interests: ["Explainable AI", "Interpretability", "Human-AI Interaction"]

# ------------------------------------------------------------------------------------------------------------
# -------------------------------------------------- FUNDING -------------------------------------------------
# ------------------------------------------------------------------------------------------------------------
major_grants:
  # Fake
  - organization: "National Science Foundation"
    title: "Robust and Interpretable AI Systems"
    amount: "$3.5 Million"
    period: "2022-2025"
    description: "This grant supports research on developing interpretable AI systems that maintain robust performance across diverse and challenging environments."
    logo: "content/artifacts/images/aisec_generic.svg"

  # Fake
  - organization: "Department of Energy"
    title: "AI Safety for Critical Infrastructure"
    amount: "$2.8 Million"
    period: "2023-2026"
    description: "This project focuses on ensuring the safety and security of AI systems deployed in critical energy infrastructure applications."
    logo: "content/artifacts/images/aisec_generic.svg"

  # Fake
  - organization: "DARPA"
    title: "Assured Autonomy Program"
    amount: "$1.9 Million"
    period: "2021-2024"
    description: "This grant supports research on formal verification methods for autonomous AI systems to ensure they operate safely within specified parameters."
    logo: "content/artifacts/images/aisec_generic.svg"

# ------------------------------------------------------------------------------------------------------------
# -------------------------------------------- INDUSTRY PARTNERS ---------------------------------------------
# ------------------------------------------------------------------------------------------------------------
industry_partners:
  - name: "Tech Company 1"
    logo: "content/artifacts/images/aisec_generic.svg"
    
  - name: "Tech Company 2"
    logo: "content/artifacts/images/aisec_generic.svg"
    
  - name: "Tech Company 3"
    logo: "content/artifacts/images/aisec_generic.svg"
    
  - name: "Tech Company 4"
    logo: "content/artifacts/images/aisec_generic.svg"
    
  - name: "Tech Company 5"
    logo: "content/artifacts/images/aisec_generic.svg"
    
  - name: "Tech Company 6"
    logo: "content/artifacts/images/aisec_generic.svg"

# ------------------------------------------------------------------------------------------------------------
# ---------------------------------------------- FOUNDATIONS -------------------------------------------------
# ------------------------------------------------------------------------------------------------------------
foundations:
  - name: "Foundation 1"
    logo: "content/artifacts/images/aisec_generic.svg"
    
  - name: "Foundation 2"
    logo: "content/artifacts/images/aisec_generic.svg"
    
  - name: "Foundation 3"
    logo: "content/artifacts/images/aisec_generic.svg"
